<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>GReaT - GReaT</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "GReaT";
        var mkdocs_page_input_path = "api-docs\\great.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> GReaT
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../getting_started/">Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">API Reference</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../">Overview</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">GReaT</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#class-great">class GReaT</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#method-great__init__">method GReaT.__init__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#method-greatfit">method GReaT.fit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#method-greatgreat_sample">method GReaT.great_sample</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#method-greatload_finetuned_model">method GReaT.load_finetuned_model</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#classmethod-greatload_from_dir">classmethod GReaT.load_from_dir</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#method-greatsample">method GReaT.sample</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#method-greatsave">method GReaT.save</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_dataset/">GReaTDataset</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_start/">GReaTStart</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../great_trainer/">GReaTTrainer</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/Example_Iris/">Example Iris</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/Example_California_Housing/">Example California Housing</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">GReaT</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>API Reference &raquo;</li>
      <li>GReaT</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <!-- markdownlint-disable -->

<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L0"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h1 id="module-great"><kbd>module</kbd> <code>great</code></h1>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L24"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h2 id="class-great"><kbd>class</kbd> <code>GReaT</code></h2>
<p>GReaT Class </p>
<p>The GReaT class handles the whole generation flow. It is used to fine-tune a large language model for tabular data, and to sample synthetic tabular data. </p>
<p><strong>Attributes:</strong></p>
<ul>
<li><b><code>llm</code></b> (str):  <a href="https://huggingface.co/models?pipeline_tag=text-generation&amp;sort=downloads">HuggingFace checkpoint</a> of a pretrained large language model, used a basis of our model </li>
<li><b><code>tokenizer</code></b> (AutoTokenizer):  Tokenizer, automatically downloaded from llm-checkpoint </li>
<li><b><code>model</code></b> (AutoModelForCausalLM):  Large language model, automatically downloaded from llm-checkpoint </li>
<li><b><code>experiment_dir</code></b> (str):  Directory, where the training checkpoints will be saved </li>
<li><b><code>epochs</code></b> (int):  Number of epochs to fine-tune the model </li>
<li><b><code>batch_size</code></b> (int):  Batch size used for fine-tuning </li>
<li><b><code>train_hyperparameters</code></b> (dict):  Additional hyperparameters added to the TrainingArguments used by the  HuggingFaceLibrary, see here the <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">full list</a> of all possible values</li>
<li><b><code>columns</code></b> (list):  List of all features/columns of the tabular dataset </li>
<li><b><code>num_cols</code></b> (list):  List of all numerical features/columns of the tabular dataset </li>
<li><b><code>conditional_col</code></b> (str):  Name of a feature/column on which the sampling can be conditioned </li>
<li><b><code>conditional_col_dist</code></b> (dict | list):  Distribution of the feature/column specified by condtional_col </li>
</ul>
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L46"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-great__init__"><kbd>method</kbd> <code>GReaT.__init__</code></h3>
<pre><code class="language-python">__init__(
    llm: str,
    experiment_dir: str = 'trainer_great',
    epochs: int = 100,
    batch_size: int = 8,
    **train_kwargs
)
</code></pre>
<p>Initializes GReaT. </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>llm</code></b>:  <a href="https://huggingface.co/models?pipeline_tag=text-generation&amp;sort=downloads">HuggingFace checkpoint</a> of a pretrained large language model, used as basis for our model </li>
<li><b><code>experiment_dir</code></b>:   Directory, where the training checkpoints will be saved </li>
<li><b><code>epochs</code></b>:  Number of epochs to fine-tune the model </li>
<li><b><code>batch_size</code></b>:  Batch size used for fine-tuning </li>
<li><b><code>train_kwargs</code></b>:  Additional hyperparameters added to the TrainingArguments used by the HuggingFaceLibrary,  see here the <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">full list</a> of all possible values  </li>
</ul>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L77"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-greatfit"><kbd>method</kbd> <code>GReaT.fit</code></h3>
<pre><code class="language-python">fit(
    data: Union[pandas.core.frame.DataFrame, numpy.ndarray],
    column_names: Optional[List[str]] = None,
    conditional_col: Optional[str] = None,
    resume_from_checkpoint: Union[bool, str] = False
) → GReaTTrainer
</code></pre>
<p>Fine-tune GReaT using tabular data. </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>data</code></b>:  Pandas DataFrame or Numpy Array that contains the tabular data </li>
<li><b><code>column_names</code></b>:  If data is Numpy Array, the feature names have to be defined. If data is Pandas DataFrame, the value is ignored </li>
<li><b><code>conditional_col</code></b>:  If given, the distribution of this column is saved and used as a starting point for the generation process later. If None, the last column is considered as conditional feature </li>
<li><b><code>resume_from_checkpoint</code></b>:  If True, resumes training from the latest checkpoint in the experiment_dir. If path, resumes the training from the given checkpoint (has to be a valid HuggingFace checkpoint!) </li>
</ul>
<p><strong>Returns:</strong>
 GReaTTrainer used for the fine-tuning process </p>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L180"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-greatgreat_sample"><kbd>method</kbd> <code>GReaT.great_sample</code></h3>
<pre><code class="language-python">great_sample(
    starting_prompts: Union[str, list[str]],
    temperature: float = 0.7,
    max_length: int = 100,
    device: str = 'cuda'
) → DataFrame
</code></pre>
<p>Generate synthetic tabular data samples conditioned on a given input. </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>starting_prompts</code></b>:  String or List of Strings on which the output is conditioned.  For example, "Sex is female, Age is 26" </li>
<li><b><code>temperature</code></b>:  The generation samples each token from the probability distribution given by a softmax  function. The temperature parameter controls the softmax function. A low temperature makes it sharper  (0 equals greedy search), a high temperature brings more diversity but also uncertainty into the output. (See this <a href="https:/huggingface.co/blog/how-to-generate">blog article</a> to read more about the generation process.) </li>
<li><b><code>max_length</code></b>:  Maximal number of tokens to generate - has to be long enough to not cut any information </li>
<li><b><code>device</code></b>:  Set to "cpu" if the GPU should not be used. You can also specify the concrete GPU. </li>
</ul>
<p><strong>Returns:</strong>
 Pandas DataFrame with synthetic data generated based on starting_prompts </p>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L248"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-greatload_finetuned_model"><kbd>method</kbd> <code>GReaT.load_finetuned_model</code></h3>
<pre><code class="language-python">load_finetuned_model(path: str)
</code></pre>
<p>Load fine-tuned model </p>
<p>Load the weights of a fine-tuned large language model into the GReaT pipeline </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>path</code></b>:  Path to the fine-tuned model </li>
</ul>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L258"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="classmethod-greatload_from_dir"><kbd>classmethod</kbd> <code>GReaT.load_from_dir</code></h3>
<pre><code class="language-python">load_from_dir(path: str)
</code></pre>
<p>Load GReaT class </p>
<p>Load trained GReaT model from directory. </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>path</code></b>:  Directory where GReaT model is saved </li>
</ul>
<p><strong>Returns:</strong>
 New instance of GReaT loaded from directory </p>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L117"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-greatsample"><kbd>method</kbd> <code>GReaT.sample</code></h3>
<pre><code class="language-python">sample(
    n_samples: int,
    start_col: Optional[str] = '',
    start_col_dist: Optional[dict, list] = None,
    temperature: float = 0.7,
    k: int = 100,
    max_length: int = 100,
    device: str = 'cuda'
) → DataFrame
</code></pre>
<p>Generate synthetic tabular data samples </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>n_samples</code></b>:  Number of synthetic samples to generate </li>
<li><b><code>start_col</code></b>:  Feature to use as starting point for the generation process. If not given, the target  learned during the fitting is used as starting point </li>
<li><b><code>start_col_dist</code></b>:  Feature distribution of the starting feature. Should have the format "{F1:  p1, F2: p2, ...}" for discrete columns or be a list of possible values for continuous columns. If not given, the target distribution learned during the fitting is used as starting point </li>
<li><b><code>temperature</code></b>:  The generation samples each token from the probability distribution given by a softmax  function. The temperature parameter controls the softmax function. A low temperature makes it sharper  (0 equals greedy search), a high temperature brings more diversity but also uncertainty into the output. (See this <a href="https:/huggingface.co/blog/how-to-generate">blog article</a> to read more about the generation process.) </li>
<li><b><code>k</code></b>:  Sampling Batch Size. Set as high as possible. Speeds up the generation process significantly </li>
<li><b><code>max_length</code></b>:  Maximal number of tokens to generate - has to be long enough to not cut any information! </li>
<li><b><code>device</code></b>:  Set to "cpu" if the GPU should not be used. You can also specify the concrete GPU </li>
</ul>
<p><strong>Returns:</strong>
 Pandas DataFrame with n_samples rows of generated data </p>
<hr />
<p><a href="https://github.com/kathrinse/be_great/tree/main/be_great\great.py#L219"><img align="right" style="float:right;" src="https://img.shields.io/badge/-source-cccccc?style=flat-square"></a></p>
<h3 id="method-greatsave"><kbd>method</kbd> <code>GReaT.save</code></h3>
<pre><code class="language-python">save(path: str)
</code></pre>
<p>Save GReaT Model </p>
<p>Saves the model weights and a configuration file in the given directory. </p>
<p><strong>Args:</strong></p>
<ul>
<li><b><code>path</code></b>:  Path where to save the model </li>
</ul>
<hr />
<p><em>This file was automatically generated via <a href="https://github.com/ml-tooling/lazydocs">lazydocs</a>.</em></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../" class="btn btn-neutral float-left" title="Overview"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../great_dataset/" class="btn btn-neutral float-right" title="GReaTDataset">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../great_dataset/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
