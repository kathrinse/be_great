import pandas as pd
import numpy as np
import os

from scipy import datasets
from be_great import GReaT

datasets_path = "/root/raha/datasets/"
# datasets =  os.listdir(datasets_path)
datasets = ['movies_1', 'hospital', 'beers', 'rayyan', 'flights', 'toy']
print("datasets:",datasets)
imputed_data_len_list = []
dirty_len_list = []
tuple_index_len_list = []
right_list = []
all_list = []
count_list = []
recall_list = []
precision_list = []
f1_list = []
for max_length in range (300,1100,100):
    for dataset in datasets:
        if dataset == 'tax':
            continue
        print("â­â­â­æ­£åœ¨å¤„ç†æ•°æ®é›†ï¼š",dataset)
        # è¯»å–ä¸¤ä¸ªCSVæ–‡ä»¶
        clean = pd.read_csv(datasets_path + dataset+'/clean.csv')
        dirty = pd.read_csv(datasets_path + dataset+'/dirty.csv')
        # æ‰‹åŠ¨æŠŠdirtyä¸­çš„é”™è¯¯å€¼æ›¿æ¢ä¸ºnp.nan
        row_index = []
        col_index = []
        tuple_index = []
        clean_dict = {}
        dirt_dict = {}
        # print(clean.iloc[1,6])
        # print(dirty.iloc[1,6])
        for i in range(len(clean)):
            for j in range(len(clean.columns)):
                if clean.iloc[i, j] != dirty.iloc[i, j]:
                    row_index.append(i)
                    col_index.append(j)
                    tuple_index.append((i, j))
                    clean_dict[(i, j)] = clean.iloc[i, j]
                    dirt_dict[(i, j)] = dirty.iloc[i, j]
                    dirty.iloc[i, j] = np.nan
        # print(tuple_index)
        # print(dirty.iloc[1,6])
        # print(clean_dict)

        model = GReaT(llm='distilgpt2', batch_size=32, epochs=25)
        model.fit(dirty)
        # synthetic_data = model.sample(n_samples=100)
        # print(synthetic_data.head())
        try:
            imputed_data = model.impute(dirty, max_length=max_length,temperature=0.1,max_retries=15,k=150) # é»˜è®¤çš„max_lengthæ˜¯200
        except Exception as e:
            print(e)
            print(f"âš âš âš åœ¨max_length={max_length}æ—¶ï¼Œå¤„ç†æ•°æ®é›†{dataset}æ—¶ï¼Œå‘ç”Ÿå¦‚ä¸Šé”™è¯¯ï¼Œè·³è¿‡")
            continue
        imputed_data.to_csv(dataset + '_imputed.csv')
        print("è¡¥å…¨å‰çš„æ•°æ®å°ºå¯¸ï¼ˆè¡Œï¼Œåˆ—ï¼‰ï¼š",dirty.shape)
        print("è¡¥å…¨åçš„æ•°æ®å°ºå¯¸ï¼ˆè¡Œï¼Œåˆ—ï¼‰ï¼š",imputed_data.shape)

        right = 0 # ç»Ÿè®¡è¡¥å…¨åçš„æ•°æ®ä¸cleanä¸­ç›¸åŒçš„å•å…ƒæ ¼ä¸ªæ•°ï¼Œå³æ­£ç¡®ä¿®æ”¹çš„ä¸ªæ•°
        all = len(tuple_index) # ç»Ÿè®¡dirtyä¸­çš„é”™è¯¯å€¼çš„ä¸ªæ•°ï¼Œå³éœ€è¦ä¿®æ”¹çš„ä¸ªæ•°
        try: # è¡¥å…¨åçš„æ•°æ®å¯èƒ½ä¼šæ¯”dirtyå°‘è‹¥å¹²è¡Œï¼Œä¸”å°‘çš„è¡Œæ•°ä¸å›ºå®š
            for tup in tuple_index:
                if imputed_data.iloc[tup[0], tup[1]] == clean.iloc[tup[0], tup[1]] :
                    print(imputed_data.iloc[tup[0], tup[1]],clean.iloc[tup[0], tup[1]])
                right += 1
        except:
            pass
        recall = right / all
        
        # ç»Ÿè®¡imputed_dataä¸dirtyä¸åŒå•å…ƒæ ¼çš„ä¸ªæ•°
        count = 0
        for i in range(min(len(dirty), len(imputed_data))):
            for j in range( min( len(dirty.columns), len(imputed_data.columns))):
                if dirty.iloc[i, j] != imputed_data.iloc[i, j]:
                    count += 1
        precision = right / count
        f1 = 2 * recall * precision / (recall + precision)
        print(f"imputed_data_len:{len(imputed_data)},dirty_len:{len(dirty)},tuple_index_len:{len(tuple_index)},right:{right},all:{all},count:{count}")
        print(f"recall:{recall},precision:{precision},f1:{f1}")
        imputed_data_len_list.append(len(imputed_data))
        dirty_len_list.append(len(dirty))
        tuple_index_len_list.append(len(tuple_index))
        right_list.append(right)
        all_list.append(all)
        count_list.append(count)
        recall_list.append(recall)
        precision_list.append(precision)
        f1_list.append(f1)
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ max_length = {max_length}")
    print(datasets)
    print(recall_list)
    print(precision_list)
    print(f1_list)